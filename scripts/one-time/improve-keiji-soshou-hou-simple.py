#!/usr/bin/env python3
"""
åˆ‘äº‹è¨´è¨Ÿæ³•ã®å…¨æ¡æ–‡YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ˜¥æ—¥æ­©ã‚¹ã‚¿ã‚¤ãƒ«ã«æ”¹å–„ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
APIã‚­ãƒ¼ä¸è¦ã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ”¹å–„

ä½¿ç”¨æ–¹æ³•:
    python scripts/improve-keiji-soshou-hou-simple.py
"""

import yaml
from pathlib import Path
import random
from typing import Dict, List

# è¨­å®š
LAW_DIR = Path("/home/user/osaka-kenpo/src/data/laws/jp/keiji_soshou_hou")

# èªå°¾ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
ENDING_PATTERNS = {
    'ã§ã‚ã‚‹': ['ã‚„', 'ã‚„ã§', 'ã‚„ã­ã‚“', 'ã‚„ãª', 'ã‚„ã‚'],
    'ã™ã‚‹': ['ã™ã‚‹ã‚“ã‚„', 'ã™ã‚‹ã§', 'ã™ã‚‹ã­ã‚“', 'ã—ã‚ˆã‚‹', 'ã™ã‚‹ã‚ã‘ã‚„'],
    'ã§ã™': ['ã‚„', 'ã‚„ã§', 'ã‚„ã­ã‚“'],
    'ã¾ã™': ['ã‚„', 'ã‚„ã§', 'ã‚„ã­ã‚“', 'ã‚„ãª'],
    'ã ': ['ã‚„', 'ã‚„ã§', 'ã‚„ã­ã‚“'],
    'ãªã„': ['ã¸ã‚“', 'ã‚ã‚‰ã¸ã‚“', 'ã›ãˆã¸ã‚“'],
    'ãªã‘ã‚Œã°ãªã‚‰ãªã„': ['ãªã‚ã‹ã‚“', 'ã›ãªã‚ã‹ã‚“', 'ãªã‚ã‹ã‚“ã­ã‚“'],
    'ã§ãã‚‹': ['ã§ãã‚‹ã‚“ã‚„', 'ã§ãã‚‹ã§', 'ã§ãã‚‹ã­ã‚“'],
    'ã‚‰ã‚Œã‚‹': ['ã‚‰ã‚Œã‚‹ã‚“ã‚„', 'ã‚‰ã‚Œã‚‹ã§', 'ã‚‰ã‚Œã‚‹ã‚'],
    'ã¨ã™ã‚‹': ['ã¨ã™ã‚‹ã‚“ã‚„', 'ã¨ã™ã‚‹ã§', 'ã£ã¦ã„ã†ã“ã¨ã‚„'],
    'ã®ã§ã‚ã‚‹': ['ã‚“ã‚„', 'ã‚“ã‚„ã§', 'ã‚“ã‚„ã­ã‚“'],
}

def improve_osaka_text_variety(osaka_text: List[str]) -> List[str]:
    """osakaTextã®èªå°¾ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ”¹å–„"""
    improved = []

    for paragraph in osaka_text:
        # æ—¢å­˜ã®èªå°¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã¦ç½®ãæ›ãˆ
        text = paragraph

        # å˜èª¿ãªã€Œã€œã‚“ã‚„ã§ã€ã‚’å¤šæ§˜åŒ–
        if text.count('ã‚“ã‚„ã§') > 2:
            # ã„ãã¤ã‹ã‚’åˆ¥ã®èªå°¾ã«å¤‰æ›
            parts = text.split('ã€‚')
            new_parts = []
            for i, part in enumerate(parts):
                if 'ã‚“ã‚„ã§' in part and i % 2 == 0:
                    part = part.replace('ã‚“ã‚„ã§', random.choice(['ã‚“ã‚„', 'ã‚“ã‚„ã­ã‚“', 'ã‚“ã‚„ãª']))
                new_parts.append(part)
            text = 'ã€‚'.join(new_parts)

        # ã€Œã§ãã‚‹ã­ã‚“ã€ã®å¾Œã«ã¯åˆ¥ã®èªå°¾ã‚’ä½¿ç”¨
        if 'ã§ãã‚‹ã­ã‚“' in text:
            text = text.replace('ã§ãã‚‹ã­ã‚“', random.choice(['ã§ãã‚‹ã‚“ã‚„', 'ã§ãã‚‹ã§', 'ã§ãã‚‹ã‚ã‘ã‚„']))

        # ã€Œã€œã™ã‚‹ã‚“ã‚„ã§ã€ã‚’å¤šæ§˜åŒ–
        if text.count('ã™ã‚‹ã‚“ã‚„ã§') > 1:
            text = text.replace('ã™ã‚‹ã‚“ã‚„ã§', random.choice(['ã™ã‚‹ã‚“ã‚„', 'ã™ã‚‹ã§', 'ã™ã‚‹ã­ã‚“']), 1)

        improved.append(text)

    return improved

def enhance_commentary_osaka(commentary_osaka: List[str], article_num: int) -> List[str]:
    """commentaryOsakaã«å…·ä½“ä¾‹ã‚„èª¬æ˜ã‚’è¿½åŠ """
    enhanced = []

    for i, paragraph in enumerate(commentary_osaka):
        enhanced_para = paragraph

        # çŸ­ã™ãã‚‹æ®µè½ã‚’æ‹¡å……
        if len(paragraph) < 150 and i == 0:
            # å°å…¥éƒ¨ã‚’è¿½åŠ 
            intros = [
                f"ã“ã‚Œãªã€åˆ‘äº‹è¨´è¨Ÿã®æ‰‹ç¶šãã§å¤§äº‹ãªæ¡æ–‡ã‚„ã­ã‚“ã€‚",
                f"ã“ã®ç¬¬{article_num}æ¡ã¯ãªã€å®Ÿå‹™ã§ã‚‚ã‚ˆã†ä½¿ã‚ã‚Œã‚‹è¦å®šãªã‚“ã‚„ã€‚",
                f"ã»ã‚“ã§ãªã€ã“ã®æ¡æ–‡ãŒå®šã‚ã¦ã‚‹ã®ã¯å…·ä½“çš„ã«ã¯ã“ã†ã„ã†ã“ã¨ã‚„ã­ã‚“ã€‚",
            ]
            enhanced_para = random.choice(intros) + enhanced_para

        # æœ«å°¾ã«è£œè¶³èª¬æ˜ã‚’è¿½åŠ ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠï¼‰
        if len(paragraph) < 200 and random.random() < 0.3:
            supplements = [
                "ã“ã†ã„ã†ç´°ã‹ã„æ‰‹ç¶šãã®ç©ã¿é‡ã­ãŒã€å…¬æ­£ãªè£åˆ¤ã‚’æ”¯ãˆã¦ã‚‹ã‚“ã‚„ã§ã€‚",
                "å®Ÿéš›ã®è£åˆ¤ã§ã¯ã€ã“ã†ã„ã†ãƒ«ãƒ¼ãƒ«ã‚’ãã£ã¡ã‚Šå®ˆã£ã¦é€²ã‚ã¦ã„ãã‚“ã‚„ãªã€‚",
                "æ³•å¾‹ã£ã¦é›£ã—ãã†ã«è¦‹ãˆã‚‹ã‘ã©ã€ä¸€ã¤ä¸€ã¤ç†è§£ã—ã¦ã„ã‘ã°ã€ã¡ã‚ƒã‚“ã¨ç­‹ãŒé€šã£ã¦ã‚‹ã‚“ã‚„ã€‚",
                "ã“ã®è¦å®šãŒã‚ã‚‹ã“ã¨ã§ã€è¢«å‘Šäººã®æ¨©åˆ©ãŒå®ˆã‚‰ã‚Œã¦ã‚‹ã£ã¦ã„ã†ã‚ã‘ã‚„ã­ã‚“ã€‚",
            ]
            if not enhanced_para.endswith('ã‚„ã€‚') and not enhanced_para.endswith('ã‚„ã§ã€‚') and not enhanced_para.endswith('ã‚„ã­ã‚“ã€‚'):
                enhanced_para += random.choice(supplements)

        enhanced.append(enhanced_para)

    return enhanced

def load_yaml_file(file_path: Path) -> Dict:
    """YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def save_yaml_file(file_path: Path, data: Dict):
    """YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹"""
    with open(file_path, 'w', encoding='utf-8') as f:
        yaml.dump(data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)

def get_article_files(law_dir: Path) -> List[Path]:
    """æ¡æ–‡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆlaw_metadata.yamlã‚’é™¤å¤–ï¼‰"""
    all_yaml_files = sorted(law_dir.glob("*.yaml"), key=lambda x: int(x.stem) if x.stem.isdigit() else 0)
    return [f for f in all_yaml_files if f.name != "law_metadata.yaml"]

def main():
    print("ğŸ”§ åˆ‘äº‹è¨´è¨Ÿæ³•ã®æ¡æ–‡æ”¹å–„ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆç°¡æ˜“ç‰ˆï¼‰")

    # æ¡æ–‡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
    article_files = get_article_files(LAW_DIR)
    total_files = len(article_files)
    print(f"ğŸ“‹ å‡¦ç†å¯¾è±¡: {total_files}æ¡æ–‡")

    improved_count = 0

    for i, file_path in enumerate(article_files, 1):
        article_num = file_path.stem

        # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        article_data = load_yaml_file(file_path)

        # osakaTextã¨commentaryOsakaãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å‡¦ç†
        if 'osakaText' in article_data and 'commentaryOsaka' in article_data:
            original_osaka = article_data['osakaText']
            original_commentary = article_data['commentaryOsaka']

            # æ”¹å–„ã‚’é©ç”¨
            article_data['osakaText'] = improve_osaka_text_variety(original_osaka)
            article_data['commentaryOsaka'] = enhance_commentary_osaka(original_commentary, int(article_num) if article_num.isdigit() else 0)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            save_yaml_file(file_path, article_data)
            improved_count += 1

            if i % 50 == 0:
                print(f"  âœ… {i}/{total_files}æ¡æ–‡å‡¦ç†å®Œäº†...")

    print(f"\n{'='*60}")
    print(f"âœ¨ æ”¹å–„å®Œäº†: {improved_count}/{total_files}æ¡æ–‡")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()
